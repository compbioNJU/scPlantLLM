{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "## MLM_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "from torch import nn\n",
    "import copy\n",
    "from loss import masked_mse_loss\n",
    "from utils import data_loader, generation_evaluate, pretrain_generation,load_config, train, evaluate, test, inference\n",
    "import datetime\n",
    "import wandb\n",
    "# sys.path.insert(0, \"../\")\n",
    "from scplantllm.model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "config = load_config('setting.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    parallel=True,\n",
    "    epochs=1, \n",
    "    batch_size=64,\n",
    "    lr=1e-4,\n",
    "    ntoken= 185622,\n",
    "    nctype= 44, \n",
    "    nbatch_effect= 238,\n",
    "    ecs_threshold=0.0, \n",
    "    layer_size=512,\n",
    "    hlayer_size=512,\n",
    "    nlayers=6,\n",
    "    nhead=8,\n",
    "    nlayers_cls=3,\n",
    "    dropout=0.5,\n",
    "    schedule_ratio=0.9, \n",
    "    save_eval_interval=5,\n",
    "    fast_transformer=True,\n",
    "    explicit_zero_prob=False,\n",
    "    pre_norm=True,\n",
    ")\n",
    "current_time = datetime.datetime.now()\n",
    "timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"test\",\n",
    "    entity=\"aibio\",\n",
    "    group=f\"{config.train_strategy}_{config.input_emb_style}\",\n",
    "    mode=\"offline\"\n",
    ")\n",
    "model_config = wandb.config\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if config.input_emb_style == \"category\":\n",
    "    n_input_bins = config.n_bins + 2 # pad_value:-2, cls_value:0, masked_value:-1\n",
    "else:\n",
    "    n_input_bins = config.n_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shy/anaconda3/envs/cgs_scplantllm/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer was not TransformerEncoderLayer\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): GeneEncoder(\n",
       "    (embedding): Embedding(185622, 512, padding_idx=0)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (value_encoder): CategoryValueEncoder(\n",
       "    (embedding): Embedding(103, 512, padding_idx=101)\n",
       "    (enc_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x FlashTransformerEncoderLayer(\n",
       "        (self_attn): FlashMHA(\n",
       "          (Wqkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (inner_attn): FlashAttention()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ExprDecoder(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (cls_decoder): ClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Ara_cls_decoder): AraClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Rice_cls_decoder): RiceClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (Maize_cls_decoder): MaizeClsDecoder(\n",
       "    (_decoder): ModuleList(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=512, out_features=44, bias=True)\n",
       "  )\n",
       "  (sim): Similarity(\n",
       "    (cos): CosineSimilarity()\n",
       "  )\n",
       "  (creterion_cce): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading model\")\n",
    "model = TransformerModel(\n",
    "    ntoken=model_config.ntoken, \n",
    "    d_model=model_config.layer_size, \n",
    "    nhead=model_config.nhead, \n",
    "    d_hid=model_config.hlayer_size,\n",
    "    nlayers=model_config.nlayers, \n",
    "    nlayers_cls=model_config.nlayers_cls, \n",
    "    n_cls=model_config.nctype, \n",
    "    dropout=model_config.dropout, \n",
    "    pad_value=int(config.pad_value),\n",
    "    pad_token_id=config.pad_token_id, \n",
    "    use_batch_labels=config.use_batch_labels, \n",
    "    num_batch_labels=model_config.nbatch_effect, \n",
    "    input_emb_style=config.input_emb_style, \n",
    "    n_input_bins= n_input_bins, \n",
    "    cell_emb_style=\"cls\", \n",
    "    use_fast_transformer=model_config.fast_transformer, \n",
    "    pre_norm=model_config.pre_norm,)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_path = 'data/processed/has_celltype'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_sampler, train_loader, train_size=model_config.metadata = data_loader(data_path, data_type='train', start_chunk=1, end_chunk=1, batch_size=model_config.batch_size, append_cls=True)\n",
    "valid_sampler, valid_loader, valid_metadata = data_loader(data_path, data_type='valid', start_chunk=1, num_chunks=1, batch_size=model_config.batch_size,append_cls=True)\n",
    "test_sampler, test_loader, test_metadata = data_loader(data_path,  data_type='test',start_chunk=1, num_chunks=1, batch_size=model_config.batch_size, append_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "criterion_gep_gepc = masked_mse_loss\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=model_config.lr, eps= 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shy/anaconda3/envs/cgs_scplantllm/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 490.48 | loss  3.29 | Scale Factor: 16384.0 | real loss: 3.29 | curl gep:  0.00 | mre 31082.99\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 494.12 | loss  2.16 | Scale Factor: 16384.0 | real loss: 2.16 | curl gep:  0.00 | mre 16229.21\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 487.44 | loss  1.99 | Scale Factor: 16384.0 | real loss: 1.99 | curl gep:  0.00 | mre 12339.96\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")\n",
    "for epoch in range(model_config.epochs):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    pretrain_generation(model, train_loader, criterion_gep_gepc, scaler, optimizer, scheduler, device, config, epoch)\n",
    "    with torch.no_grad():\n",
    "        val_loss = generation_evaluate(model, valid_loader, criterion_gep_gepc, device, config, epoch)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "    save_path = f'./model_param/{config.train_strategy}'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(save_path, f\"{timestamp}_{config.input_emb_style}_model_{epoch}.pth\")\n",
    "    # torch.save(model.module.state_dict(), checkpoint_path)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        best_model_name = f\"best_model_{config.input_emb_style}_{best_model_epoch}_{timestamp}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 211.82380628585815 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print(f\"Total time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "metadata": {}
   },
   "source": [
    "## CLS_pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model_name = f\"./model_params/scPlantLLM_model.pth\"\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "except:\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_name)\n",
    "    pretrained_dict = {\n",
    "            k: v\n",
    "            for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape\n",
    "        }\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "criterion_gep_gepc = masked_mse_loss\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_dab = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=model_config.lr, eps=1e-4 if config.amp else 1e-8\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=config.amp)\n",
    "best_val_loss = float(\"inf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | train/accuracy: 0.79546875, train/error_rate: 0.21453125\n",
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 500.44 | loss 51709.86 | scale factor: 32768.0 |scaled loss  1.58 |cls  1.31 | \n",
      "| epoch   0 | 200/356 batches | train/accuracy: 0.93015625, train/error_rate: 0.06984375\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 482.80 | loss 7034.68 | scale factor: 32768.0 |scaled loss  0.21 |cls  0.21 | \n",
      "| epoch   0 | 300/356 batches | train/accuracy: 0.9328125, train/error_rate: 0.0671875\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 439.30 | loss 6845.37 | scale factor: 32768.0 |scaled loss  0.21 |cls  0.21 | \n",
      "Epoch 0 time: 163.0573172569275\n",
      "valid/loss: 91665.9375, valid/cls: 0.003290872199853, valid/accuracy: 0.9342105263157895, valid/precision: 0.9230882822477018, valid/recall: 0.9104830924928804, valid/macro_f1: 0.9152900094932492, valid/micro_f1: 0.9342105263157895\n",
      "Train time: 380.6561756134033\n",
      "Train finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(model_config.epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, train_loader, criterion_gep_gepc, criterion_dab, criterion_cls, scaler, optimizer, scheduler, device, config,  epoch, model_config.parallel)\n",
    "    epoch_end_time = time.time()\n",
    "    print(f\"Epoch {epoch} time: {epoch_end_time - epoch_start_time}\")\n",
    "    \n",
    "    val_loss = evaluate(model, test_loader, criterion_gep_gepc, criterion_dab, criterion_cls, device, config, epoch)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    timestamp = current_time.strftime(\"%YY%mM%dD%HH%MM%SS\")\n",
    "    save_path = f'./model_param/{config.train_strategy}'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(save_path, f\"{timestamp}_{config.input_emb_style}_model_{epoch}.pth\")\n",
    "    # torch.save(model.module.state_dict(), checkpoint_path)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_model_epoch = epoch\n",
    "        best_model_name = f\"best_model_{config.input_emb_style}_{best_model_epoch}_{timestamp}.pth\"\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Train time: {end_time - start_time}\")\n",
    "print(\"Train finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "celltype_vocab_path = f'data/processed/has_celltype/cell_type_vocab.meta.json'\n",
    "with open(celltype_vocab_path) as f:\n",
    "        celltype_vocab = json.load(f)\n",
    "celltype_vocab = {value : key for key, value in celltype_vocab.items()} \n",
    "batch_effect_vocab_file = f'data/processed/has_celltype/batch_effect_vocab.meta.json'\n",
    "with open(batch_effect_vocab_file) as f:\n",
    "        batch_effect_vocab = json.load(f)\n",
    "batch_effect_vocab  = {value : key for key, value in batch_effect_vocab.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | 100/356 batches | train/accuracy: 0.95, train/error_rate: 0.06\n",
      "| epoch   0 | 100/356 batches | lr 0.00010 | ms/batch 413.25 | loss 11988.32 | scale factor: 65536.0 |scaled loss  0.18 |cls  0.18 | \n",
      "| epoch   0 | 200/356 batches | train/accuracy: 0.95734375, train/error_rate: 0.04265625\n",
      "| epoch   0 | 200/356 batches | lr 0.00010 | ms/batch 403.45 | loss 8567.25 | scale factor: 65536.0 |scaled loss  0.13 |cls  0.13 | \n",
      "| epoch   0 | 300/356 batches | train/accuracy: 0.95125, train/error_rate: 0.04875\n",
      "| epoch   0 | 300/356 batches | lr 0.00010 | ms/batch 395.58 | loss 9403.54 | scale factor: 65536.0 |scaled loss  0.14 |cls  0.14 | \n",
      "Epoch 0 time: 143.29024934768677\n",
      "valid/loss: 68070.09375, valid/cls: 0.002264972477477338, valid/accuracy: 0.9588815789473685, valid/precision: 0.9478250416583902, valid/recall: 0.9407023940006436, valid/macro_f1: 0.9413680357006167, valid/micro_f1: 0.9588815789473685\n"
     ]
    }
   ],
   "source": [
    "fine_tune = True\n",
    "if fine_tune:\n",
    "    criterion_gep_gepc = masked_mse_loss\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    criterion_dab = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=model_config.lr, eps=1e-4 if config.amp else 1e-8)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=model_config.schedule_ratio)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.amp)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    for epoch in range(model_config.epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model, train_loader, criterion_gep_gepc, criterion_dab, criterion_cls, scaler, optimizer, scheduler, device, config,  epoch, model_config.parallel)\n",
    "            epoch_end_time = time.time()\n",
    "            print(f\"Epoch {epoch} time: {epoch_end_time - epoch_start_time}\")\n",
    "    \n",
    "            val_loss = evaluate(model, valid_loader, criterion_gep_gepc, criterion_dab, criterion_cls, device, config, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/accuracy: 0.944078947368421, test/precision: 0.938828142548302, test/recall: 0.914617949871456, test/macro_f1: 0.924546586675447, test/micro_f1: 0.944078947368421\n",
      "[3, 3, 7, 3, 8]\n",
      "[3, 3, 7, 3, 8]\n",
      "Using time to predict: 8.770305871963501\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cell_types_predictions, cell_types_labels, cell_names, probabilities, cell_embeddings, batch_labels_list = test(model, test_loader, test_metadata, device, config)\n",
    "predict_end_time = time.time()\n",
    "print(cell_types_predictions[:5])\n",
    "print(cell_types_labels[:5])\n",
    "print(f\"Using time to predict: {predict_end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using time to predict: 8.455778360366821\n",
      "[3, 3, 7, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cell_types_predictions, _, cell_names, probabilities, cell_embeddings, batch_labels_list = inference(model, test_loader, test_metadata, device, config)\n",
    "predict_end_time = time.time()\n",
    "print(f\"Using time to predict: {predict_end_time - start_time}\")\n",
    "print(cell_types_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgs_scplantllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
